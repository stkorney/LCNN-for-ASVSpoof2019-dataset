{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12653593,"sourceType":"datasetVersion","datasetId":7996648}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n    #for filename in filenames:\n        #print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-06T14:20:22.557930Z","iopub.execute_input":"2025-08-06T14:20:22.558540Z","iopub.status.idle":"2025-08-06T14:20:22.563799Z","shell.execute_reply.started":"2025-08-06T14:20:22.558514Z","shell.execute_reply":"2025-08-06T14:20:22.562974Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nimport wandb\n\nuser_secrets = UserSecretsClient()\nsecret_value_1 = user_secrets.get_secret(\"wandb-key\")\n\nwandb.login(key=secret_value_1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T14:20:22.565016Z","iopub.execute_input":"2025-08-06T14:20:22.565319Z","iopub.status.idle":"2025-08-06T14:20:22.722919Z","shell.execute_reply.started":"2025-08-06T14:20:22.565304Z","shell.execute_reply":"2025-08-06T14:20:22.722335Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"import torch\nfrom torch import nn\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n%config InlineBackend.figure_format='retina'\nimport seaborn as sns\nsns.set_style(\"whitegrid\")\nimport torchaudio\nfrom torch.utils.data import DataLoader, Dataset\nimport random\nimport os\nfrom IPython import display\nfrom tqdm import tqdm\nimport csv\nimport wandb ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T14:20:22.723600Z","iopub.execute_input":"2025-08-06T14:20:22.723866Z","iopub.status.idle":"2025-08-06T14:20:22.733387Z","shell.execute_reply.started":"2025-08-06T14:20:22.723841Z","shell.execute_reply":"2025-08-06T14:20:22.732682Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"def save_predictions(predictions, filename=\"predictions.csv\"):\n    with open(filename, 'w', newline='') as csvfile:\n        writer = csv.writer(csvfile)\n        for file_id, score in predictions.items():\n            writer.writerow([file_id, f\"{score:.5f}\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T14:20:22.734802Z","iopub.execute_input":"2025-08-06T14:20:22.735037Z","iopub.status.idle":"2025-08-06T14:20:22.749092Z","shell.execute_reply.started":"2025-08-06T14:20:22.735022Z","shell.execute_reply":"2025-08-06T14:20:22.748360Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"epochs = 2 # Вынесено в отдельную переменную для тестов\nruns = 1 # В training recipe было указано 6, но, как я понял, нам это делать и сравнивать результаты не нужно. На всякий случай вынесено в отдельную переменную.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T15:53:32.611223Z","iopub.execute_input":"2025-08-06T15:53:32.611577Z","iopub.status.idle":"2025-08-06T15:53:32.615449Z","shell.execute_reply.started":"2025-08-06T15:53:32.611556Z","shell.execute_reply":"2025-08-06T15:53:32.614685Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"class MyDataset(Dataset):\n    def __init__(self, data_type=\"train\"):\n        self.files = []\n        self.data_type = data_type\n        self.path = os.path.join(\"/kaggle/input/asvspoof2019-la\", \"LA\", f\"ASVspoof2019_LA_{data_type}/flac\")\n        \n        if data_type == \"train\": # Не понял почему, но в train папке данный файл по-другому называется, поэтому нужно выделять отдельный случай\n             name = \"ASVspoof2019.LA.cm.train.trn.txt\"\n        else:\n            name = f\"ASVspoof2019.LA.cm.{data_type}.trl.txt\"\n        \n        self.protocol_file = os.path.join(\"/kaggle/input/asvspoof2019-la\", \"LA\", \"ASVspoof2019_LA_cm_protocols\", name)\n\n        files = []\n        with open(self.protocol_file, 'r') as f:\n            for line in f:\n                parts = line.strip().split()\n                file_name = parts[1] + '.flac'\n                if parts[4] == \"spoof\":\n                    val = 0\n                else:\n                    val = 1\n                files.append((file_name, val))\n        self.files = files\n\n    def __getitem__(self, index):\n        file_name, label = self.files[index]\n        file_path = os.path.join(self.path, file_name)\n\n        inpt, sr = torchaudio.load(file_path)\n        if sr != 16000:\n            resampler = torchaudio.transforms.Resample(sr, 16000)\n            inpt = resampler(inpt)\n\n        spectrogram = self.FFT(inpt)\n        base_name = file_name.replace('.flac', '')\n        return spectrogram, label, base_name\n    \n    def FFT(self, inpt):\n        spec = torch.stft(input=inpt, n_fft=2048, hop_length=512, win_length=2048, window=torch.hann_window(2048), return_complex=True) # Используем готовый SFTF\n        spec = torch.log(torch.abs(spec) + 1e-9) # Логарифм как в статье\n\n        # Придаем нужную форму, чтобы при выполнении не выдало ошибку\n        \n        _, freq, time = spec.shape\n        if freq > 864:\n            spec = spec[:, :864, :]\n        else:\n            spec = torch.nn.functional.pad(spec, (0, 0, 0, 864 - freq))\n        if time > 600:\n            spec = spec[:, :, :600]\n        else:\n            spec = torch.nn.functional.pad(spec, (0, 600 - time, 0, 0))\n        \n        return spec\n\n    def __len__(self):\n        return len(self.files)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T14:20:22.765085Z","iopub.execute_input":"2025-08-06T14:20:22.765323Z","iopub.status.idle":"2025-08-06T14:20:22.783500Z","shell.execute_reply.started":"2025-08-06T14:20:22.765302Z","shell.execute_reply":"2025-08-06T14:20:22.782844Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"class MFM(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n    def forward(self, x):\n        halves = torch.split(x, x.size(1)//2, dim=1)\n        return torch.max(halves[0], halves[1])\n\nclass MyModel(nn.Module):\n    def __init__(self, in_channels=1, num_classes=2):\n        super().__init__()\n\n        self.net = nn.Sequential(\n            nn.Conv2d(1, 64, kernel_size=5, stride=1, padding=2, bias=False),\n            MFM(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            \n            nn.Conv2d(32, 64, kernel_size=1, stride=1, padding=0, bias=False),\n            MFM(),\n            nn.BatchNorm2d(32),\n            \n            nn.Conv2d(32, 96, kernel_size=3, stride=1, padding=1, bias=False),\n            MFM(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.BatchNorm2d(48),\n            \n            nn.Conv2d(48, 96, kernel_size=1, stride=1, padding=0, bias=False),\n            MFM(),\n            nn.BatchNorm2d(48),\n            nn.Conv2d(48, 128, kernel_size=3, stride=1, padding=1, bias=False),\n            MFM(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            \n            nn.Conv2d(64, 128, kernel_size=1, stride=1, padding=0, bias=False),\n            MFM(),\n            nn.BatchNorm2d(64),\n            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1, bias=False),\n            MFM(),\n            nn.BatchNorm2d(32),\n            nn.Conv2d(32, 64, kernel_size=1, stride=1, padding=0, bias=False),\n            MFM(),\n            nn.BatchNorm2d(32),\n            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1, bias=False),\n            MFM(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            \n            nn.Flatten(),\n            \n            nn.Linear(32 * 54 * 37, 160),\n            MFM(),\n            nn.BatchNorm1d(80),\n            nn.Dropout(p=0.5), # Т.к. сказали добавить dropout\n            nn.Linear(80, 2)\n        )\n\n\n    def forward(self, input_data):\n        return self.net(input_data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T14:20:22.784503Z","iopub.execute_input":"2025-08-06T14:20:22.784766Z","iopub.status.idle":"2025-08-06T14:20:22.805640Z","shell.execute_reply.started":"2025-08-06T14:20:22.784749Z","shell.execute_reply":"2025-08-06T14:20:22.805027Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"def set_random_seed(seed):\n    torch.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    np.random.seed(seed)\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n\n    print(f\"Seed: {seed}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T14:20:22.806243Z","iopub.execute_input":"2025-08-06T14:20:22.806429Z","iopub.status.idle":"2025-08-06T14:20:22.824302Z","shell.execute_reply.started":"2025-08-06T14:20:22.806414Z","shell.execute_reply":"2025-08-06T14:20:22.823688Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"def train_one_epoch(model, dataloader, criterion, optimizer, \n                    device, metrics_logs, total_steps, curr_epoch):\n    model.train()\n    epoch_loss = 0.0\n    correct = 0\n    total = 0\n    avg_loss = 0.0\n    \n    for batch_idx, (inpt, label, file_id) in tqdm(enumerate(dataloader), total=len(dataloader), desc=\"Training\"):\n        # ОСНОВНАЯ ЧАСТЬ\n        \n        inpt, label = inpt.to(device), label.to(device)\n\n        output = model(inpt)\n        loss = criterion(output, label)\n        \n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n        # СЧИТАЕМ/ИЗМЕНЯЕМ ПЕРЕМЕННЫЕ ДЛЯ МЕТРИК\n        \n        epoch_loss += loss.item()\n        _, predicted = torch.max(output, 1)\n        total += label.size(0)\n        correct += (predicted == label).sum().item()\n        step_correct = (predicted == label).sum().item()\n        step_total = label.size(0)\n        step_acc = 100 * step_correct / step_total\n        total_steps += 1\n\n        # СОХРАНЯЕМ МЕТРИКИ\n        \n        wandb.log({\"train loss vs step\": loss.item(),\n                   \"train accuracy vs step\": step_acc, \"train epoch vs step\": curr_epoch\n        }, step=total_steps)\n\n    avg_loss = epoch_loss / (batch_idx + 1)\n    epoch_acc = 100 * correct / total\n    return avg_loss, epoch_acc, total_steps\n\ndef evaluate(model, dataloader, criterion, device, return_predictions=False, curr_step=None):\n    model.eval()\n    epoch_loss = 0.0\n    correct = 0\n    total = 0\n    avg_loss = 0\n    answs = []\n    prdns = []\n    file_ids = []\n    predictions_dict = {} \n    \n    for batch_idx, (inpt, label, file_id) in tqdm(enumerate(dataloader), total=len(dataloader), desc=\"Evaluating\"):\n        inpt, label = inpt.to(device), label.to(device)\n        \n        with torch.no_grad():\n            # ОСНОВНАЯ ЧАСТЬ\n            \n            output = model(inpt)\n            loss = criterion(output, label)\n\n            # СНОВА КУЧА ПЕРЕМЕННЫХ ДЛЯ МЕТРИК\n            \n            epoch_loss += loss.item()\n            _, predicted = torch.max(output, 1)\n            total += label.size(0)\n            correct += (predicted == label).sum().item()\n            \n            scores = torch.softmax(output, dim=1)[:, 1]\n            answs.extend(label.cpu().numpy())\n            prdns.extend(scores.cpu().numpy())\n            file_ids.extend(file_id)\n    \n    avg_loss = epoch_loss / (batch_idx + 1)\n    accuracy = 100 * correct / total\n\n    # Считаем EER\n    bonafide_scores = np.array([prdns[i] for i in range(len(answs)) if answs[i] == 1])\n    spoof_scores = np.array([prdns[i] for i in range(len(answs)) if answs[i] == 0])\n    eer, _ = compute_eer(bonafide_scores, spoof_scores)\n    eer *= 100\n    \n    if return_predictions: # Для финальной оценки модели на eval датасете\n        # Записываем предсказания\n        for i, file_id in enumerate(file_ids):\n            predictions_dict[file_id] = prdns[i]\n            \n        # Сохраняем данные в wandb\n        wandb.log({\"eval loss\": avg_loss, \"eval accuracy\": accuracy, \"eval eer\": eer})\n        \n        return avg_loss, accuracy, eer, predictions_dict\n    else: # Для запусков evaluate после тренировки каждой эпохи на dev датасете\n        # Записываем предсказания (Только для финальной версии)\n        for i, file_id in enumerate(file_ids):\n            predictions_dict[file_id] = prdns[i]\n        csv_filename = f\"predictions_{curr_step}.csv\"\n        save_predictions(predictions_dict, csv_filename)\n        print(f\"Predictions: {csv_filename}\")\n        \n        wandb.log({\"eval loss vs step\": avg_loss, \"eval accuracy vs step\": accuracy,\n            \"eval eer vs step\": eer}, step=curr_step)\n        return avg_loss, accuracy, eer\n\ndef train(model, train_dataloader, dev_dataloader, optimizer, criterion, scheduler, device, epochs, metrics_logs, total_steps):\n\n    epoch = 0\n    while epoch < epochs:\n        train_loss, train_acc, total_steps = train_one_epoch(model, train_dataloader, criterion, \n                                                             optimizer, device, metrics_logs, total_steps, curr_epoch=epoch)\n\n        \n        if (epoch + 1) % 2 == 0 or epoch == epochs - 1 or epoch < 3: \n            # Говорили делать val через две эпохи, но у меня тогда мало данных для графиков\n            val_loss, val_acc, val_eer = evaluate(model, dev_dataloader, criterion, device,\n                                                  curr_step=total_steps)\n        else:\n            val_loss, val_acc, val_eer = None, None, None\n        \n        scheduler.step()\n        \n        #Выводим логи\n        log_str = f\"Epoch {epoch+1}: \"\n        log_str += f\"train loss = {train_loss:.4f} train acc = {train_acc:.2f}% \"\n        if val_acc is not None:\n            log_str += f\"eval loss = {val_loss:.4f} eval acc = {val_acc:.2f}% eval eer = {val_eer:.2f}%\"\n        print(log_str)\n\n        if epoch == epochs - 1:\n            print(\"Continue? (1 or 0)\")\n            ans_count = int(input())\n            epochs += ans_count\n\n        epoch += 1\n    \n    return model, metrics_logs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T15:53:39.933569Z","iopub.execute_input":"2025-08-06T15:53:39.933849Z","iopub.status.idle":"2025-08-06T15:53:39.948584Z","shell.execute_reply.started":"2025-08-06T15:53:39.933829Z","shell.execute_reply":"2025-08-06T15:53:39.948090Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"def compute_det_curve(target_scores, nontarget_scores):\n\n    n_scores = target_scores.size + nontarget_scores.size\n    all_scores = np.concatenate((target_scores, nontarget_scores))\n    labels = np.concatenate(\n        (np.ones(target_scores.size), np.zeros(nontarget_scores.size)))\n\n    # Sort labels based on scores\n    indices = np.argsort(all_scores, kind='mergesort')\n    labels = labels[indices]\n\n    # Compute false rejection and false acceptance rates\n    tar_trial_sums = np.cumsum(labels)\n    nontarget_trial_sums = nontarget_scores.size - \\\n        (np.arange(1, n_scores + 1) - tar_trial_sums)\n\n    # false rejection rates\n    frr = np.concatenate(\n        (np.atleast_1d(0), tar_trial_sums / target_scores.size))\n    far = np.concatenate((np.atleast_1d(1), nontarget_trial_sums /\n                          nontarget_scores.size))  # false acceptance rates\n    # Thresholds are the sorted scores\n    thresholds = np.concatenate(\n        (np.atleast_1d(all_scores[indices[0]] - 0.001), all_scores[indices]))\n\n    return frr, far, thresholds\n\n\ndef compute_eer(bonafide_scores, other_scores):\n    \"\"\" \n    Returns equal error rate (EER) and the corresponding threshold.\n    \"\"\"\n    frr, far, thresholds = compute_det_curve(bonafide_scores, other_scores)\n    abs_diffs = np.abs(frr - far)\n    min_index = np.argmin(abs_diffs)\n    eer = np.mean((frr[min_index], far[min_index]))\n    return eer, thresholds[min_index]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T14:20:22.847897Z","iopub.execute_input":"2025-08-06T14:20:22.848195Z","iopub.status.idle":"2025-08-06T14:20:22.868911Z","shell.execute_reply.started":"2025-08-06T14:20:22.848178Z","shell.execute_reply":"2025-08-06T14:20:22.868396Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"wandb.init(\n    project=\"ASVspoof2019_final\",\n    config={\"learning_rate\": 3e-4, \"batch_size\": 8,\n            \"epochs\": epochs, \"architecture\": \"LCNN\"}\n)\n    \ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nresults = []\neval_results = []\n    \nfor run in range(1, runs + 1):\n    # Изначально использовался метод получения seed из статьи\n    # seed = 10 ** (run - 1)\n    seed = random.randint(1, 100000)\n    #seed = 96498\n    set_random_seed(seed)\n\n    # Параметры для локальных графиков, в финальной версии не используются\n    metrics_logs = {'train_acc_by_step': [], 'train_loss_by_step': [], 'val_loss_by_step': [], 'val_acc_by_step': [], 'val_eer_by_step': [],\n                'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [], 'val_eer': []}\n    total_steps = 0\n\n    # ОБУЧЕНИЕ\n        \n    model = MyModel().to(device)\n    train_dataset = MyDataset(data_type=\"train\")\n    dev_dataset = MyDataset(data_type=\"dev\")\n    eval_dataset = MyDataset(data_type=\"eval\")\n\n    train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True, pin_memory=True)\n    dev_dataloader = DataLoader(dev_dataset, batch_size=8, shuffle=False)\n    eval_dataloader = DataLoader(eval_dataset, batch_size=8, shuffle=False)\n\n    optimizer = torch.optim.Adam(model.parameters(), lr=3e-4, betas=(0.9, 0.999), eps=1e-8) \n    criterion = nn.CrossEntropyLoss()\n    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n    # Параметры выше взяты из статьи с Training recipe\n    \n    trained_model, run_logs = train(\n        model=model,\n        train_dataloader=train_dataloader,\n        dev_dataloader=eval_dataloader,\n        optimizer=optimizer,\n        criterion=criterion,\n        scheduler=scheduler,\n        device=device,\n        epochs=epochs,\n        metrics_logs=metrics_logs,\n        total_steps=total_steps\n    )\n\nwandb.log({\n    \"seed\": seed\n})\n\nwandb.finish()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T15:53:48.790977Z","iopub.execute_input":"2025-08-06T15:53:48.791278Z","iopub.status.idle":"2025-08-06T16:09:15.979940Z","shell.execute_reply.started":"2025-08-06T15:53:48.791259Z","shell.execute_reply":"2025-08-06T16:09:15.978652Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.20.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250806_155348-nze8z9n3</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/stepankorny-hse/ASVspoof2019_final/runs/nze8z9n3' target=\"_blank\">resilient-cherry-12</a></strong> to <a href='https://wandb.ai/stepankorny-hse/ASVspoof2019_final' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/stepankorny-hse/ASVspoof2019_final' target=\"_blank\">https://wandb.ai/stepankorny-hse/ASVspoof2019_final</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/stepankorny-hse/ASVspoof2019_final/runs/nze8z9n3' target=\"_blank\">https://wandb.ai/stepankorny-hse/ASVspoof2019_final/runs/nze8z9n3</a>"},"metadata":{}},{"name":"stdout","text":"Seed: 94097\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 3173/3173 [12:28<00:00,  4.24it/s]\nEvaluating:  26%|██▌       | 2313/8905 [02:52<08:10, 13.43it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/955001786.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;31m# Параметры выше взяты из статьи с Training recipe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     trained_model, run_logs = train(\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/3073818500.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_dataloader, dev_dataloader, optimizer, criterion, scheduler, device, epochs, metrics_logs, total_steps)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0;31m# Говорили делать val через две эпохи, но у меня тогда мало данных для графиков\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             val_loss, val_acc, val_eer = evaluate(model, dev_dataloader, criterion, device,\n\u001b[0m\u001b[1;32m    115\u001b[0m                                                   curr_step=total_steps)\n\u001b[1;32m    116\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/3073818500.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, dataloader, criterion, device, return_predictions, curr_step)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mpredictions_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minpt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Evaluating\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0minpt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             if (\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/2587055103.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0minpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minpt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mspectrogram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFFT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minpt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mbase_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.flac'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mspectrogram\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/2587055103.py\u001b[0m in \u001b[0;36mFFT\u001b[0;34m(self, inpt)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mFFT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minpt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mspec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minpt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_fft\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2048\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhop_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwin_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2048\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhann_window\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2048\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_complex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Используем готовый SFTF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mspec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1e-9\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Логарифм как в статье\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;31m# Придаем нужную форму, чтобы при выполнении не выдало ошибку\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":32},{"cell_type":"code","source":"\"\"\"\n# ФИНАЛЬНАЯ ОЦЕНКА МОДЕЛИ НА EVAL\n        \neval_loss, eval_acc, eval_eer, eval_predictions  = evaluate(trained_model, eval_loader, criterion, device,\n                                                return_predictions=True)\n\n# ЛОГИ И ВЫВОД РЕЗУЛЬТАТОВ\n        \nwandb.log({\n    \"eval loss\": eval_loss,\n    \"eval accuracy\": eval_acc,\n    \"eval eer\": eval_eer,\n    \"seed\": seed\n})\ncsv_filename = f\"predictions.csv\"\nsave_predictions(eval_predictions, csv_filename)\nprint(f\"Predictions: {csv_filename}\")\n        \nprint(f\"Results: loss = {eval_loss:.4f}, acc = {eval_acc:.4f}%, eer = {eval_eer:.4f}%\")\n\nresults.append(run_logs)\neval_results.append({'loss': eval_loss, 'acc': eval_acc, 'eer': eval_eer})\n\nwandb.finish()\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T15:52:12.300567Z","iopub.execute_input":"2025-08-06T15:52:12.300871Z","iopub.status.idle":"2025-08-06T15:52:12.306332Z","shell.execute_reply.started":"2025-08-06T15:52:12.300840Z","shell.execute_reply":"2025-08-06T15:52:12.305616Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"'\\n# ФИНАЛЬНАЯ ОЦЕНКА МОДЕЛИ НА EVAL\\n        \\neval_loss, eval_acc, eval_eer, eval_predictions  = evaluate(trained_model, eval_loader, criterion, device,\\n                                                return_predictions=True)\\n\\n# ЛОГИ И ВЫВОД РЕЗУЛЬТАТОВ\\n        \\nwandb.log({\\n    \"eval loss\": eval_loss,\\n    \"eval accuracy\": eval_acc,\\n    \"eval eer\": eval_eer,\\n    \"seed\": seed\\n})\\ncsv_filename = f\"predictions.csv\"\\nsave_predictions(eval_predictions, csv_filename)\\nprint(f\"Predictions: {csv_filename}\")\\n        \\nprint(f\"Results: loss = {eval_loss:.4f}, acc = {eval_acc:.4f}%, eer = {eval_eer:.4f}%\")\\n\\nresults.append(run_logs)\\neval_results.append({\\'loss\\': eval_loss, \\'acc\\': eval_acc, \\'eer\\': eval_eer})\\n\\nwandb.finish()\\n'"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"\"\"\"\ndef test_eer():\n    bonafide = np.random.normal(0.8, 0.1, 1000)  # Низкие значения\n    spoof = np.random.normal(0.2, 0.1, 1000)      # Высокие значения\n    eer, _ = compute_eer(bonafide, spoof)\n    print(f\"Expected low EER, got: {eer:.4f}\")\n\n    bonafide = np.random.uniform(0, 1, 1000)\n    spoof = np.random.uniform(0, 1, 1000)\n    eer, _ = compute_eer(bonafide, spoof)\n    print(f\"Expected ~0.5 EER, got: {eer:.4f}\")\n\ntest_eer()\n\"\"\"","metadata":{"trusted":true,"scrolled":true,"execution":{"iopub.status.busy":"2025-08-06T15:52:12.307302Z","iopub.execute_input":"2025-08-06T15:52:12.307568Z","iopub.status.idle":"2025-08-06T15:52:12.324971Z","shell.execute_reply.started":"2025-08-06T15:52:12.307545Z","shell.execute_reply":"2025-08-06T15:52:12.324202Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"'\\ndef test_eer():\\n    bonafide = np.random.normal(0.8, 0.1, 1000)  # Низкие значения\\n    spoof = np.random.normal(0.2, 0.1, 1000)      # Высокие значения\\n    eer, _ = compute_eer(bonafide, spoof)\\n    print(f\"Expected low EER, got: {eer:.4f}\")\\n\\n    bonafide = np.random.uniform(0, 1, 1000)\\n    spoof = np.random.uniform(0, 1, 1000)\\n    eer, _ = compute_eer(bonafide, spoof)\\n    print(f\"Expected ~0.5 EER, got: {eer:.4f}\")\\n\\ntest_eer()\\n'"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"\n\nprint(\"Содержимое рабочей директории:\")\nprint(os.listdir('/kaggle/working/'))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T15:52:12.325811Z","iopub.execute_input":"2025-08-06T15:52:12.326496Z","iopub.status.idle":"2025-08-06T15:52:12.339752Z","shell.execute_reply.started":"2025-08-06T15:52:12.326475Z","shell.execute_reply":"2025-08-06T15:52:12.339072Z"}},"outputs":[{"name":"stdout","text":"Содержимое рабочей директории:\n['predictions_9519.csv', 'predictions_6346.csv', 'wandb', 'predictions_3173.csv', '.virtual_documents']\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"\nfrom IPython.display import FileLink\nFileLink('predictions_6346.csv')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T15:52:12.340530Z","iopub.execute_input":"2025-08-06T15:52:12.340823Z","iopub.status.idle":"2025-08-06T15:52:12.357385Z","shell.execute_reply.started":"2025-08-06T15:52:12.340798Z","shell.execute_reply":"2025-08-06T15:52:12.356582Z"}},"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/predictions_6346.csv","text/html":"<a href='predictions_6346.csv' target='_blank'>predictions_6346.csv</a><br>"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"\"\"\"\nfrom IPython.display import Image, display\n\n# Для step_metrics.png\ndisplay(Image(filename='/kaggle/working/step_metrics.png', width=1000))\n\n# Для training_results.png\ndisplay(Image(filename='/kaggle/working/training_results.png', width=1000))\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T15:52:12.358237Z","iopub.execute_input":"2025-08-06T15:52:12.358443Z","iopub.status.idle":"2025-08-06T15:52:12.373710Z","shell.execute_reply.started":"2025-08-06T15:52:12.358427Z","shell.execute_reply":"2025-08-06T15:52:12.373109Z"}},"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"\"\\nfrom IPython.display import Image, display\\n\\n# Для step_metrics.png\\ndisplay(Image(filename='/kaggle/working/step_metrics.png', width=1000))\\n\\n# Для training_results.png\\ndisplay(Image(filename='/kaggle/working/training_results.png', width=1000))\\n\""},"metadata":{}}],"execution_count":28}]}